---
title: "Applied AI Consulting"
sidebar: false
image: cover_2.png
aliases: ["hire/", "hire"]
repo-actions: false
---

We are [experienced AI Engineers](team.qmd) who have built AI products at leading tech companies.

# Services

## Tier 1: Strategy

We will advise you on:

-   LLM performance issues: (cost, quality, speed)
-   Evals, RAG, Fine-Tuning, and Prompt Engineering
-   Unblock your team with focused debugging sessions and education.

We will give your team ongoing feedback and guidance via regular meetings, saving them time and money. 

## Tier 2: Comprehensive

Everything in Tier 1, plus:

-  **Implementation:** We will write production-ready code to accelerate your AI product development.
-  **Model Optimization:** We will implement domain-specific eval systems, fine-tune, prompt engineer and debug models to improve performance.
-  **Tools and Infrastructure:** We will implement tools that will enable you to execute consistently and quickly on your AI products.
- **A full-time presence of 2+ FTEs** from [our team](https://parlance-labs.com/team.html) to work on your project.

# Pricing

The cost depends on the tier of service:

- Strategy: $36,500 for a 2-month engagement.
- Comprehensive (2+ FTEs): $725,900 total for a 3-month engagement.

We also provide custom pricing for longer engagements or specific projects.

**Contact us at `consultingl@parlance-labs.com` or fill out [this form](https://llms.typeform.com/to/M8f89mlM) to discuss starting an engagement.**

# Current & Past Clients

::: {.callout-tip collapse="true"}
## Expand To See Clients

Members of [our team](team.qmd) have worked with the following companies:

- [Limitless AI](http://limitless.ai/): Limitless AI is a personal memory assistant that helps you remember, organize, and navigate your life.
- [Raycast](https://raycast.com/): Raycast is a blazingly fast, totally extendable launcher. It lets you complete tasks, calculate, share common links, and much more.
- [Tensorlake](https://tensorlake.ai/): Build Knowledge for LLMs from un-structured data
-   [Replicate](https://replicate.com/): development of fine-tuning serverless infrastructure using axolotl and optimized LLM inference.
-   [Weights & Biases](https://wandb.ai/site): Provide product guidance for evaluation, annotation, and observability.
-   [Honeycomb](https://www.honeycomb.io/): Currently improving the [natural language query assistant](https://www.honeycomb.io/blog/introducing-query-assistant) through evaluation systems and fine-tuning.
-   [LangChain/LangSmith](https://www.langchain.com): provided product guidance for enterprise LLM tools.
-   [Modal](https://modal.com/): Serverless tools for fine-tuning.
-   [Rechat](https://rechat.com/): We are working on Lucy, a conversational AI for real estate agents. You can read about my recent work on Rechat [here](https://hamel.dev/blog/posts/evals/).
-   [Answer.ai](https://www.answer.ai/): Conduct research on new LLM applications and help with product strategy.
-   [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl): Hamel is a core contributor to axolotl, a library for efficient fine-tuning of LLMs.
- [Kay.ai](http://kay.ai/): Retrieve relevant context from the semantic web for your LLM apps with fully hosted embeddings.
- [Modal Labs](https://modal.com/): Modal specializes in cloud functions, offering a platform for running generative AI models, large-scale batch jobs, and more.
- [Pydantic](http://pydantic.dev/): Pydantic provides data validation and settings management using Python type annotations, enforcing type hints at runtime with user-friendly error handling.
-   [Posit](https://posit.co/): Helped Posit expand into the Python AI and ML ecosystem.
-   [Catena](https://www.catena.xyz/): LLM infrastructure such as routing, evaluation, and orchestration.
- [Arize AI](https://arize.com/llm/): We are helping Arize with LLM observability and evaluation tools.
- [dbt Labs](getdbt.com): Helping dbt build natural language to SQL interfaces, data analysis/engineering co-pilots, and more.
- [Radiant AI](https://radiantai.com/): We helped the Radiant team accelerate the development of their LLM observability platform.
:::